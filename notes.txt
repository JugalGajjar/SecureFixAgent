Research Title: Hybrid LLM Agents for Python Static Vulnerability Detection and Automated Repair
Project Name: SecureFixAgent

Background:
───────────
Static analysis tools like Bandit and SonarQube offer rule-based precision for detecting vulnerabilities in code, but they often suffer from rigidity, high false positives, and limited ability to explain or repair issues. Conversely, LLMs such as DeepSeek Coder, Qwen, and CodeGemma demonstrate strong flexibility in code understanding and generation but can lack precision, context-awareness, and reliability when used alone.

This research proposes a hybrid agent that combines static analyzers and small, local LLMs to achieve high-quality detection and repair of Python security vulnerabilities.

Research Goal:
──────────────
To enhance static vulnerability detection and automated repair in Python code by developing an intelligent LLM-based agent that collaborates with traditional static analysis tools, specifically Bandit. The proposed agent will leverage lightweight, open-source code-oriented LLMs (≤8B parameters) to classify, explain, and generate secure fixes for vulnerabilities detected in Python programs. Beyond single-shot patching, the agent will perform iterative self-correction, decide when to re-run Bandit for validation, and autonomously determine whether additional repair attempts are required—thereby exhibiting core properties of reasoning and autonomy expected in modern AI agents. This research focuses on integrating static analysis outputs with LLM reasoning to improve real-world code security in a low-latency, local setting.

Research Questions:
───────────────────
1. Can lightweight open-source LLMs (≤8B parameters) reliably identify, explain, and repair code vulnerabilities in Python when guided by static analyzers like Bandit?
2. Does incorporating an agentic control loop featuring Bandit-based revalidation, retry logic, and iterative self-correction improve the quality and completeness of vulnerability fixes?
3. How do different open-source LLMs (e.g., DeepSeek Coder V2, Qwen 2.5 Coder, CodeGemma 7B) compare in terms of vulnerability detection, explanation, and repair accuracy in the proposed setup?
4. Can the proposed hybrid agent generalize to real-world Python repositories containing diverse vulnerability patterns, beyond synthetic or benchmark datasets?

LLM Agent Capabilities:
───────────────────────
1. Classification: Label issue as ─► True Positive │ False Positive │ True Negative │ False Negative │ Not Sure
2. Explanation: Generate a concise, CWE-style explanation of the vulnerability.
3. Fix Generation: Rewrite the code to patch the issue, maintaining functionality.

LLM Agent Architecture:
───────────────────────

   ┌──────────────┐
   │  Python Code │
   └──────────────┘
          │
          ▼
   ┌──────────────┐
   │  Bandit Scan │────────► Vulnerability Metadata
   └──────────────┘
          │
          ▼
   ┌──────────────────────────────┐
   │        LLM Agent Core        │
   ├──────────┬─────────┬─────────┤
   │ Classify │ Explain │   Fix   │
   └──────────┴─────────┴─────────┘
          │
          ▼
   ┌───────────────────────────────┐
   │ Re-run Bandit for validation? │
   └───────────────────────────────┘
          │
          ▼
   If issues remain ─► Retry Fix (max 5 iterations)

Tools & Technologies:
─────────────────────

│ Component		│ Choice							│
│ ──────────────────────│ ──────────────────────────────────────────────────────────────│
│ Static Analyzer	│ Bandit (Python security issues				│
│ Instruct LLMs (≤8B)	│ DeepSeek Coder 1.3B/6.7B, Qwen 2.5 Coder 3B/7B, CodeLlama 7B	│
│ Inference		│ HuggingFace Transformers, Ollama, Apple MLX			│
│ Programming Language	│ Python							│
│ Dataset Format	│ Python files or snippets with vulnerabilities			│

Agent Loop Enhancements:
────────────────────────
1. Re-Validation Decision: After a patch is applied, the LLM is asked:
“Should we re-run Bandit to validate the fix?”
If yes ─► Bandit is rerun.

2. Iterative Patching: If Bandit still reports the issue, the agent:
- Re-prompts itself with previous patch + Bandit report
- Attempts a new fix
- Loop continues up to 5 iterations max

This loop enables autonomous self-correction.

Evaluation Metrics:
───────────────────

│ Aspect              │ Metric						│
│ ─────────────────── │ ────────────────────────────────────────────────│
│ Fix accuracy        │ % of successful patches (Bandit no longer flags)│
│ Precision           │ Correct vs incorrect classifications (FP, TP)	│
│ Iteration count     │ Avg. attempts required per fix			│
│ Explanation quality │ Manual rating					│
